{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtlSwrMhiljI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXdkRzcRil19"
      },
      "source": [
        "### Importing packages and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9gUs_lnhaMNz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import stack\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "import seaborn as sns; sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B6YK9Y-q2xD",
        "outputId": "30b04b19-2f30-42b1-d7e1-f152d36640b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "df_train = pd.read_csv(\"gdrive/My Drive/fashion-mnist_train.csv\")\n",
        "df_test = pd.read_csv(\"gdrive/My Drive/fashion-mnist_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "I2qkMuswuIlf",
        "outputId": "7fdfb7b2-c8c6-4e3a-91d1-fdbe8853531e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      2       0       0       0       0       0       0       0       0   \n",
              "1      9       0       0       0       0       0       0       0       0   \n",
              "2      6       0       0       0       0       0       0       0       5   \n",
              "3      0       0       0       0       1       2       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       0  ...         0         0         0         0         0         0   \n",
              "1       0  ...         0         0         0         0         0         0   \n",
              "2       0  ...         0         0         0        30        43         0   \n",
              "3       0  ...         3         0         0         0         0         1   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e660cb1-fc4a-4f38-a82d-b554ee9ad476\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e660cb1-fc4a-4f38-a82d-b554ee9ad476')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e660cb1-fc4a-4f38-a82d-b554ee9ad476 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e660cb1-fc4a-4f38-a82d-b554ee9ad476');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_6UyorAcvTc6"
      },
      "outputs": [],
      "source": [
        "y_train = df_train[[\"label\"]]\n",
        "df_train = df_train.to_numpy()\n",
        "X_train = df_train[:,1:].reshape(df_train.shape[0],28,28).astype( 'float32' )\n",
        "X_train = X_train/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLVNI8kc43St",
        "outputId": "e3377bae-b878-44cd-c248-d43cc7235f43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMulHG0o41U-",
        "outputId": "da2f6a84-7f8a-42c6-eeec-0bb0c7aa99f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyCkfnb_w8Mr",
        "outputId": "cfedf296-e8c4-4c07-93a5-2fbd665857a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9DSmZ-uww_Nr"
      },
      "outputs": [],
      "source": [
        "df_valid, df_test = df_test[:5000], df_test[5000:] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eGsvA0J4Cy54"
      },
      "outputs": [],
      "source": [
        "y_test = df_test[[\"label\"]]\n",
        "df_test = df_test.to_numpy()\n",
        "X_test = df_test[:,1:].reshape(df_test.shape[0],28,28).astype( 'float32' )\n",
        "X_test = X_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcybxGi4E3X7",
        "outputId": "f18b5780-b1c1-408f-9f7a-a77d803c23f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGo0-n0M8tn5",
        "outputId": "e9f5ec1e-a161-417e-e86a-716508f26538"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y_valid = df_valid[[\"label\"]]\n",
        "df_valid = df_valid.to_numpy()\n",
        "X_valid = df_valid[:,1:].reshape(df_valid.shape[0],28,28).astype( 'float32' )\n",
        "X_test = X_test/255.0\n",
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "X-VMlcdy1pit",
        "outputId": "c97f08ac-07b2-4d5d-ab5d-f1ebbaf2a081"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "image = X_train[0]\n",
        "fig = plt.figure\n",
        "plt.imshow(image, cmap = 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHLtWEimi34f"
      },
      "source": [
        "### Defining a baseline CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GUWdGjMe7p2Z"
      },
      "outputs": [],
      "source": [
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [60, 30, 25] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate=0):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", \n",
        "                                  input_shape=[28, 28, 1]))    # input layer goes into this 2D convolution\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "    model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yvnOGBx9HDv"
      },
      "outputs": [],
      "source": [
        "# early stopping callback to help set a limit of runs\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "MfxYdY8x8g2l"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_cnn(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJK2kde59Hp7",
        "outputId": "89e7dcce-a63f-4bba-e4a1-bae7eeb149f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 125s 66ms/step - loss: 0.4445 - accuracy: 0.8417 - val_loss: 33.6246 - val_accuracy: 0.8801\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 122s 65ms/step - loss: 0.2980 - accuracy: 0.8929 - val_loss: 24.0453 - val_accuracy: 0.9018\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 123s 66ms/step - loss: 0.2577 - accuracy: 0.9068 - val_loss: 32.2996 - val_accuracy: 0.8673\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 124s 66ms/step - loss: 0.2338 - accuracy: 0.9153 - val_loss: 25.6315 - val_accuracy: 0.8916\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 122s 65ms/step - loss: 0.2133 - accuracy: 0.9223 - val_loss: 23.6020 - val_accuracy: 0.8814\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 122s 65ms/step - loss: 0.1982 - accuracy: 0.9276 - val_loss: 37.0744 - val_accuracy: 0.8712\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 120s 64ms/step - loss: 0.1845 - accuracy: 0.9334 - val_loss: 31.9678 - val_accuracy: 0.8635\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 60)        600       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 60)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 30)        16230     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 30)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 25)          6775      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1225)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                12260     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,865\n",
            "Trainable params: 35,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDO6mXjJiYPf"
      },
      "source": [
        "### CNN: Model comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dku8TEJjjkm_"
      },
      "source": [
        "###### I decided to increase the hidden sizes. First I tested a smaller learning rate. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PghK31VgYRPr"
      },
      "outputs": [],
      "source": [
        "# Model 1 with LR 0.0001\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [100, 30, 20] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.0001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "    model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut0RlGDGYTKe",
        "outputId": "7856bf88-11c4-4989-cf16-0177d0813146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 172s 92ms/step - loss: 0.7456 - accuracy: 0.7320 - val_loss: 65.2549 - val_accuracy: 0.7717\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 171s 91ms/step - loss: 0.4815 - accuracy: 0.8278 - val_loss: 49.7254 - val_accuracy: 0.8214\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.4259 - accuracy: 0.8490 - val_loss: 54.3202 - val_accuracy: 0.8304\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.3951 - accuracy: 0.8591 - val_loss: 56.3273 - val_accuracy: 0.8176\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.3718 - accuracy: 0.8681 - val_loss: 61.1163 - val_accuracy: 0.8240\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 171s 91ms/step - loss: 0.3534 - accuracy: 0.8745 - val_loss: 50.0909 - val_accuracy: 0.8355\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.3379 - accuracy: 0.8808 - val_loss: 59.1187 - val_accuracy: 0.8214\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.3253 - accuracy: 0.8855 - val_loss: 71.3922 - val_accuracy: 0.8112\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 169s 90ms/step - loss: 0.3141 - accuracy: 0.8886 - val_loss: 52.9495 - val_accuracy: 0.8355\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.3060 - accuracy: 0.8912 - val_loss: 51.8126 - val_accuracy: 0.8342\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 100)       1000      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 30)        27030     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 30)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 20)          5420      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 980)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                9810      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,260\n",
            "Trainable params: 43,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ebBcpSl9BB"
      },
      "source": [
        "###### Accuracy appeared to improve using the same LR as the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhNuSe1UfYwr"
      },
      "outputs": [],
      "source": [
        "# Model 2 \n",
        "# Baseline with LR 0.001\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [100, 30, 20] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "    model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h_I3kOQfaTV",
        "outputId": "0438ffaf-1f95-49b8-8087-f93147be5eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 171s 91ms/step - loss: 0.4540 - accuracy: 0.8348 - val_loss: 41.5182 - val_accuracy: 0.8469\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 173s 92ms/step - loss: 0.3061 - accuracy: 0.8912 - val_loss: 32.7186 - val_accuracy: 0.8737\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.2641 - accuracy: 0.9047 - val_loss: 31.1569 - val_accuracy: 0.8967\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 177s 94ms/step - loss: 0.2380 - accuracy: 0.9130 - val_loss: 30.3425 - val_accuracy: 0.8916\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 175s 93ms/step - loss: 0.2176 - accuracy: 0.9208 - val_loss: 30.3917 - val_accuracy: 0.8916\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 173s 92ms/step - loss: 0.2024 - accuracy: 0.9266 - val_loss: 29.2807 - val_accuracy: 0.8980\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 173s 92ms/step - loss: 0.1890 - accuracy: 0.9319 - val_loss: 30.4892 - val_accuracy: 0.8929\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 172s 92ms/step - loss: 0.1773 - accuracy: 0.9353 - val_loss: 40.5827 - val_accuracy: 0.8712\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 169s 90ms/step - loss: 0.1653 - accuracy: 0.9391 - val_loss: 39.2501 - val_accuracy: 0.8712\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 167s 89ms/step - loss: 0.1566 - accuracy: 0.9433 - val_loss: 49.2400 - val_accuracy: 0.8457\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 100)       1000      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 30)        27030     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 7, 7, 30)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 20)          5420      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 980)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                9810      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,260\n",
            "Trainable params: 43,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "TKixabdzkoUk"
      },
      "outputs": [],
      "source": [
        "# Model 3 \n",
        "# strides = 2\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [100, 30, 20] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=2, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=2, padding=\"same\", activation=actfn))\n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=2, padding=\"same\", activation=actfn))\n",
        "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "    model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBWiiEU4ko4y",
        "outputId": "3e18d86e-0ec8-4b51-de64-df50fbcf066f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.6206 - accuracy: 0.7778 - val_loss: 46.6157 - val_accuracy: 0.8189\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.3986 - accuracy: 0.8576 - val_loss: 44.9667 - val_accuracy: 0.8202\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.3488 - accuracy: 0.8738 - val_loss: 54.9032 - val_accuracy: 0.7985\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.3192 - accuracy: 0.8854 - val_loss: 63.0643 - val_accuracy: 0.7768\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.3000 - accuracy: 0.8917 - val_loss: 52.3403 - val_accuracy: 0.8202\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2860 - accuracy: 0.8981 - val_loss: 80.7530 - val_accuracy: 0.7742\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2732 - accuracy: 0.9019 - val_loss: 86.4077 - val_accuracy: 0.7500\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_25 (Conv2D)          (None, 14, 14, 100)       1000      \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 7, 7, 100)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 4, 4, 30)          27030     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 2, 2, 30)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 1, 1, 20)          5420      \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,660\n",
            "Trainable params: 33,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBfbL93ulhGQ"
      },
      "outputs": [],
      "source": [
        "# Model 4 \n",
        "# Extra Max Pooling layer\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [100, 30, 20] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn))\n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=1, strides=3, padding=\"same\", activation=actfn))\n",
        "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "    model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d55KQmh5liCH",
        "outputId": "92c4a5bc-7a83-41c2-e874-832aa71d4b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.9963 - accuracy: 0.6185 - val_loss: 81.4844 - val_accuracy: 0.6339\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.7678 - accuracy: 0.7110 - val_loss: 83.1422 - val_accuracy: 0.6671\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.7190 - accuracy: 0.7295 - val_loss: 76.9605 - val_accuracy: 0.6543\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.6886 - accuracy: 0.7405 - val_loss: 79.1466 - val_accuracy: 0.6454\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.6668 - accuracy: 0.7468 - val_loss: 90.0846 - val_accuracy: 0.6429\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 108s 58ms/step - loss: 0.6480 - accuracy: 0.7540 - val_loss: 86.0161 - val_accuracy: 0.6212\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 107s 57ms/step - loss: 0.6340 - accuracy: 0.7590 - val_loss: 77.9605 - val_accuracy: 0.6531\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 100)       1000      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 7, 7, 100)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 7, 7, 30)          27030     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 3, 3, 30)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 1, 1, 20)          620       \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,860\n",
            "Trainable params: 28,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB9czq2rlraN"
      },
      "outputs": [],
      "source": [
        "# Model 5 \n",
        "# two convolutional layers\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [100, 30, 20] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "    model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKM7bKw3lsg0",
        "outputId": "1db814ea-128f-4a89-ba15-65d5d445a5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 806s 430ms/step - loss: 0.4231 - accuracy: 0.8475 - val_loss: 23.6156 - val_accuracy: 0.8801\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 803s 428ms/step - loss: 0.2752 - accuracy: 0.9017 - val_loss: 21.6873 - val_accuracy: 0.8673\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 807s 430ms/step - loss: 0.2362 - accuracy: 0.9148 - val_loss: 33.5941 - val_accuracy: 0.8304\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 809s 431ms/step - loss: 0.2098 - accuracy: 0.9222 - val_loss: 22.9450 - val_accuracy: 0.8635\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 811s 432ms/step - loss: 0.1873 - accuracy: 0.9308 - val_loss: 22.8133 - val_accuracy: 0.8571\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 810s 432ms/step - loss: 0.1689 - accuracy: 0.9388 - val_loss: 25.3612 - val_accuracy: 0.8686\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 28, 28, 100)       1000      \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 28, 28, 100)       90100     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 14, 14, 100)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 14, 14, 30)        27030     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 7, 7, 30)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 7, 7, 20)          5420      \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 980)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                9810      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,360\n",
            "Trainable params: 133,360\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_59WciSwxAcF"
      },
      "outputs": [],
      "source": [
        "# Model 6 \n",
        "# relu activation function in dense layer\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [100, 30, 20] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "    model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "    model.add(keras.layers.Dense(10, activation = \"relu\"))  # 10 classes for this dataset\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SOnXlwtxA6Q",
        "outputId": "ab13a9e1-ec42-49e1-a4bb-a36e48bc5e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 177s 94ms/step - loss: 2.3512 - accuracy: 0.1027 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 176s 94ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 172s 92ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 171s 91ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 169s 90ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 166s 88ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 28, 28, 100)       1000      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 100)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 14, 14, 30)        27030     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 7, 7, 30)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 7, 7, 20)          5420      \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 980)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                9810      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,260\n",
            "Trainable params: 43,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y7bAKvrz-sf"
      },
      "outputs": [],
      "source": [
        "# Model 7 \n",
        "# two convolutional layers and two convolutional hidden layers\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [100, 30, 20] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn))\n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "        model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))\n",
        "        model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "        model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUkQ5mFD0LzG",
        "outputId": "2a920adc-185f-4a79-8280-38a94d9730ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 827s 441ms/step - loss: 0.4298 - accuracy: 0.8457 - val_loss: 23.1169 - val_accuracy: 0.8878\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 830s 443ms/step - loss: 0.2741 - accuracy: 0.9011 - val_loss: 19.6854 - val_accuracy: 0.8916\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 834s 445ms/step - loss: 0.2348 - accuracy: 0.9150 - val_loss: 15.0602 - val_accuracy: 0.8814\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 852s 454ms/step - loss: 0.2102 - accuracy: 0.9238 - val_loss: 22.8583 - val_accuracy: 0.8801\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 834s 445ms/step - loss: 0.1918 - accuracy: 0.9289 - val_loss: 25.2183 - val_accuracy: 0.8406\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 832s 444ms/step - loss: 0.1737 - accuracy: 0.9369 - val_loss: 27.8370 - val_accuracy: 0.8559\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 827s 441ms/step - loss: 0.1615 - accuracy: 0.9412 - val_loss: 24.9898 - val_accuracy: 0.8890\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 28, 28, 100)       1000      \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 28, 28, 100)       90100     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 14, 14, 100)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 14, 14, 30)        27030     \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 14, 14, 30)        8130      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 7, 7, 30)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 7, 7, 20)          5420      \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 980)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                9810      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 141,490\n",
            "Trainable params: 141,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-3BVqiklaJO"
      },
      "source": [
        "### A competing approach: Dense Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L3K4JjR-rEC8"
      },
      "outputs": [],
      "source": [
        "# DNN Model 1\n",
        "# Baseline DNN with one layer and softmax\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [100, 30, 20]  # testing out one extra layer\n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))    \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CAIh7wH2q4ts"
      },
      "outputs": [],
      "source": [
        "# early stopping callback to help set a limit of runs\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u3MCAbrAq71E"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mKb3zhWeq-2V",
        "outputId": "15a9ddfc-3377-4ab4-96e7-bbe84bf72dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5547 - accuracy: 0.8073 - val_loss: 73.0373 - val_accuracy: 0.8227\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3905 - accuracy: 0.8586 - val_loss: 49.5263 - val_accuracy: 0.8571\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3572 - accuracy: 0.8695 - val_loss: 50.9310 - val_accuracy: 0.8520\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3351 - accuracy: 0.8783 - val_loss: 58.0798 - val_accuracy: 0.8495\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3176 - accuracy: 0.8828 - val_loss: 54.1371 - val_accuracy: 0.8457\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3035 - accuracy: 0.8883 - val_loss: 41.6137 - val_accuracy: 0.8686\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2919 - accuracy: 0.8916 - val_loss: 55.6136 - val_accuracy: 0.8508\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2814 - accuracy: 0.8957 - val_loss: 71.9072 - val_accuracy: 0.8214\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2708 - accuracy: 0.9000 - val_loss: 47.4260 - val_accuracy: 0.8763\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2645 - accuracy: 0.9013 - val_loss: 57.1901 - val_accuracy: 0.8367\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2549 - accuracy: 0.9041 - val_loss: 53.7472 - val_accuracy: 0.8520\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2486 - accuracy: 0.9068 - val_loss: 60.4676 - val_accuracy: 0.8546\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2421 - accuracy: 0.9097 - val_loss: 63.5166 - val_accuracy: 0.8469\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2364 - accuracy: 0.9107 - val_loss: 51.2782 - val_accuracy: 0.8673\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 30)                3030      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 25)                525       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,675\n",
            "Trainable params: 82,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YVK7a7sdEWIy"
      },
      "outputs": [],
      "source": [
        "# DNN Model 2\n",
        "# two dense hidden layers in preactivation\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [100, 30, 20]  # testing out one extra layer\n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))   \n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))    \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DnPEb1IZEXHm"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TN-DGY5eEYKq",
        "outputId": "9bc67583-2a12-4b69-8356-90e091e993b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5937 - accuracy: 0.7982 - val_loss: 54.0141 - val_accuracy: 0.8457\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3999 - accuracy: 0.8574 - val_loss: 45.4137 - val_accuracy: 0.8686\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3592 - accuracy: 0.8700 - val_loss: 51.4301 - val_accuracy: 0.8648\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3340 - accuracy: 0.8785 - val_loss: 41.4029 - val_accuracy: 0.8622\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3138 - accuracy: 0.8845 - val_loss: 51.2458 - val_accuracy: 0.8622\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3014 - accuracy: 0.8882 - val_loss: 46.7191 - val_accuracy: 0.8737\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2894 - accuracy: 0.8930 - val_loss: 51.2893 - val_accuracy: 0.8622\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2790 - accuracy: 0.8967 - val_loss: 60.3933 - val_accuracy: 0.8457\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2684 - accuracy: 0.8997 - val_loss: 50.6538 - val_accuracy: 0.8622\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2604 - accuracy: 0.9028 - val_loss: 55.5708 - val_accuracy: 0.8406\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2526 - accuracy: 0.9059 - val_loss: 61.6683 - val_accuracy: 0.8393\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 30)                3030      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 25)                525       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,675\n",
            "Trainable params: 82,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Test the above model\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-YLBL7HZ2KUY"
      },
      "outputs": [],
      "source": [
        "# DNN Model 3\n",
        "# two dense layers in preactivation\n",
        "\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [100, 30, 20]  # testing out one extra layer\n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))\n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\"))  \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a9xrTMPc2Ovy"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ylRayYaH2QT8",
        "outputId": "3c568e46-a7d1-4d3e-e035-3ef64ab244e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6202 - accuracy: 0.7844 - val_loss: 60.0574 - val_accuracy: 0.8380\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4054 - accuracy: 0.8554 - val_loss: 60.0390 - val_accuracy: 0.8444\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3625 - accuracy: 0.8686 - val_loss: 46.6277 - val_accuracy: 0.8559\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3381 - accuracy: 0.8771 - val_loss: 51.1106 - val_accuracy: 0.8393\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3236 - accuracy: 0.8820 - val_loss: 53.8793 - val_accuracy: 0.8559\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3084 - accuracy: 0.8862 - val_loss: 45.6585 - val_accuracy: 0.8559\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2952 - accuracy: 0.8919 - val_loss: 45.9286 - val_accuracy: 0.8635\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2851 - accuracy: 0.8961 - val_loss: 62.7301 - val_accuracy: 0.8457\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2763 - accuracy: 0.8981 - val_loss: 45.9056 - val_accuracy: 0.8610\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2667 - accuracy: 0.9010 - val_loss: 65.4588 - val_accuracy: 0.8316\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2591 - accuracy: 0.9040 - val_loss: 56.9458 - val_accuracy: 0.8571\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2515 - accuracy: 0.9060 - val_loss: 52.7346 - val_accuracy: 0.8533\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 30)                3030      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 25)                525       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 94,125\n",
            "Trainable params: 94,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SkDugopMxAKO"
      },
      "outputs": [],
      "source": [
        "# DNN Model 4\n",
        "# two dense layers in preactivation\n",
        "# two dense hidden layers in forward propogation\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [100, 30, 20]  # testing out one extra layer\n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))  \n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))    \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\"))  \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ePDCBvfexC74"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DtC6gaduxFah",
        "outputId": "fedf4b77-6fd3-40ae-88c3-503220ea0d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6149 - accuracy: 0.7856 - val_loss: 45.0254 - val_accuracy: 0.8508\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4047 - accuracy: 0.8554 - val_loss: 49.2977 - val_accuracy: 0.8482\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3651 - accuracy: 0.8673 - val_loss: 52.0758 - val_accuracy: 0.8469\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3392 - accuracy: 0.8778 - val_loss: 40.4182 - val_accuracy: 0.8597\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3202 - accuracy: 0.8845 - val_loss: 52.3122 - val_accuracy: 0.8418\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3069 - accuracy: 0.8879 - val_loss: 46.2915 - val_accuracy: 0.8469\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2924 - accuracy: 0.8925 - val_loss: 35.5741 - val_accuracy: 0.8571\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2831 - accuracy: 0.8945 - val_loss: 41.8814 - val_accuracy: 0.8610\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2744 - accuracy: 0.8996 - val_loss: 38.1541 - val_accuracy: 0.8852\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2643 - accuracy: 0.9029 - val_loss: 45.5239 - val_accuracy: 0.8559\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2581 - accuracy: 0.9042 - val_loss: 50.1957 - val_accuracy: 0.8622\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2478 - accuracy: 0.9085 - val_loss: 46.0336 - val_accuracy: 0.8686\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2424 - accuracy: 0.9100 - val_loss: 53.6815 - val_accuracy: 0.8482\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2379 - accuracy: 0.9121 - val_loss: 57.1604 - val_accuracy: 0.8304\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_12 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 30)                3030      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 25)                525       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 94,125\n",
            "Trainable params: 94,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4zdgLWgN6yvG"
      },
      "outputs": [],
      "source": [
        "# DNN Model 5\n",
        "# relu activation in foward propogation\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [100, 30, 20]  # testing out one extra layer\n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# best learning rate as per the tests below\n",
        "learningrate = 0.001 # best learning rate as found below\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))  \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(10, activation = \"relu\"))  \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aQk97gTZ6zyi"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gNPM1_om600a",
        "outputId": "3687e184-e9fd-445f-f18d-5922080a9419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.4937 - accuracy: 0.1450 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3064 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_14 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 30)                3030      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,360\n",
            "Trainable params: 82,360\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Test the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OYdpO0p768GY"
      },
      "outputs": [],
      "source": [
        "# DNN Model 6\n",
        "# Original DNN with increased hidden layer sizes\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [1000, 300, 200] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.001 \n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1])) \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CNO-HScJ6892"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e8Kg-i_i7QjQ",
        "outputId": "c0442c3e-4ad7-48e9-e294-fd5908f4e506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.4918 - accuracy: 0.8225 - val_loss: 42.8082 - val_accuracy: 0.8597\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.3690 - accuracy: 0.8647 - val_loss: 38.1493 - val_accuracy: 0.8610\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.3312 - accuracy: 0.8773 - val_loss: 38.1442 - val_accuracy: 0.8827\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.3041 - accuracy: 0.8874 - val_loss: 42.1049 - val_accuracy: 0.8801\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.2868 - accuracy: 0.8934 - val_loss: 36.4761 - val_accuracy: 0.8827\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.2704 - accuracy: 0.8997 - val_loss: 46.6699 - val_accuracy: 0.8661\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.2599 - accuracy: 0.9028 - val_loss: 49.9859 - val_accuracy: 0.8546\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2461 - accuracy: 0.9067 - val_loss: 53.0374 - val_accuracy: 0.8469\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_15 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1000)              785000    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 300)               300300    \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 200)               60200     \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 25)                5025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,150,525\n",
            "Trainable params: 1,150,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bbIXP36n7Xw1"
      },
      "outputs": [],
      "source": [
        "# DNN Model 7\n",
        "# Baseline with increased batch size\n",
        "# increased hidden layer size\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [1000, 300, 200]  # testing out one extra layer\n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# best learning rate as per the tests below\n",
        "learningrate = 0.001 # best learning rate as found below\n",
        "# size of batch and number of epochs\n",
        "batch_size = 100\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))   \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\"))   \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JjMZB7o569so"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WijE5HMA7Y24",
        "outputId": "e5c12caf-875b-446d-8d7a-396bd98a9e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.4911 - accuracy: 0.8216 - val_loss: 51.6129 - val_accuracy: 0.8393\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.3716 - accuracy: 0.8650 - val_loss: 41.0632 - val_accuracy: 0.8457\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.3304 - accuracy: 0.8784 - val_loss: 37.8704 - val_accuracy: 0.8776\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.3081 - accuracy: 0.8850 - val_loss: 49.7821 - val_accuracy: 0.8520\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2880 - accuracy: 0.8923 - val_loss: 43.3660 - val_accuracy: 0.8610\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2750 - accuracy: 0.8959 - val_loss: 48.2491 - val_accuracy: 0.8635\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2617 - accuracy: 0.9017 - val_loss: 48.8119 - val_accuracy: 0.8661\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2509 - accuracy: 0.9058 - val_loss: 46.2441 - val_accuracy: 0.8673\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1000)              785000    \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 300)               300300    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 200)               60200     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 25)                5025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,150,525\n",
            "Trainable params: 1,150,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jIYYDQj270cQ"
      },
      "outputs": [],
      "source": [
        "# DNN Model 8\n",
        "# baseline with increased hidden layer size\n",
        "# more epochs\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [1000, 300, 200]  # testing out one extra layer\n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# best learning rate as per the tests below\n",
        "learningrate = 0.001 # best learning rate as found below\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 100\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1]))   \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\"))  \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "86ehgQVa71WF"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "O5q_cLGp-OuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deaa6946-3c02-4e8e-9f3c-b5db66e9c96f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.4932 - accuracy: 0.8217 - val_loss: 46.9897 - val_accuracy: 0.8648\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.3703 - accuracy: 0.8655 - val_loss: 53.0990 - val_accuracy: 0.8278\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.3326 - accuracy: 0.8783 - val_loss: 47.4716 - val_accuracy: 0.8597\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.3061 - accuracy: 0.8878 - val_loss: 43.3303 - val_accuracy: 0.8724\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2897 - accuracy: 0.8918 - val_loss: 46.2517 - val_accuracy: 0.8610\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2760 - accuracy: 0.8960 - val_loss: 34.9231 - val_accuracy: 0.8916\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2607 - accuracy: 0.9022 - val_loss: 50.8181 - val_accuracy: 0.8661\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2491 - accuracy: 0.9056 - val_loss: 38.5304 - val_accuracy: 0.8903\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2397 - accuracy: 0.9087 - val_loss: 39.3911 - val_accuracy: 0.8763\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2297 - accuracy: 0.9119 - val_loss: 43.8817 - val_accuracy: 0.8635\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2223 - accuracy: 0.9165 - val_loss: 53.2836 - val_accuracy: 0.8712\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              785000    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 300)               300300    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               60200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 25)                5025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,150,525\n",
            "Trainable params: 1,150,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FgQ5WfUE72DV"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4pA4N56mDmo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuZ3Ovb0mD3d"
      },
      "source": [
        "### Final model comparison and run on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzAGcNGDuTrz"
      },
      "source": [
        "###### Starting with CNN:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 using new hidden sizes\n",
        "# Baseline with LR 0.0001\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.0001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "        model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "        model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "        model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ],
      "metadata": {
        "id": "x1-xKym5Tj4K"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_cnn(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ],
      "metadata": {
        "id": "1EFqebapTmuD"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQuE9PYWToAw",
        "outputId": "9060ede3-d694-48a5-e44d-7884cf549d0d"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 112s 59ms/step - loss: 0.6467 - accuracy: 0.7716 - val_loss: 47.3778 - val_accuracy: 0.8304\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.4231 - accuracy: 0.8494 - val_loss: 41.8094 - val_accuracy: 0.8444\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 113s 60ms/step - loss: 0.3732 - accuracy: 0.8681 - val_loss: 37.9819 - val_accuracy: 0.8724\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 131s 70ms/step - loss: 0.3440 - accuracy: 0.8784 - val_loss: 38.6070 - val_accuracy: 0.8712\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 117s 62ms/step - loss: 0.3225 - accuracy: 0.8857 - val_loss: 34.2565 - val_accuracy: 0.8801\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.3046 - accuracy: 0.8912 - val_loss: 39.4642 - val_accuracy: 0.8635\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.2895 - accuracy: 0.8967 - val_loss: 40.5277 - val_accuracy: 0.8635\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.2782 - accuracy: 0.9013 - val_loss: 34.0324 - val_accuracy: 0.8750\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.2687 - accuracy: 0.9041 - val_loss: 36.2462 - val_accuracy: 0.8737\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.2587 - accuracy: 0.9080 - val_loss: 35.8667 - val_accuracy: 0.8724\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 7, 7, 96)          55392     \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 4704)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                47050     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,258\n",
            "Trainable params: 121,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "YiPC2wtXtEFc"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    # Plot the results (shifting validation curves appropriately)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    n = len(history.history['accuracy'])\n",
        "    plt.plot(np.arange(0,n),history.history['accuracy'], color='orange')\n",
        "    plt.plot(np.arange(0,n),history.history['loss'],'b')\n",
        "    plt.plot(np.arange(0,n)+0.5,history.history['val_accuracy'],'r')  # offset both validation curves\n",
        "    plt.plot(np.arange(0,n)+0.5,history.history['val_loss'],'g')\n",
        "    plt.legend(['Train Acc','Train Loss','Val Acc','Val Loss'])\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0, 1) # set the vertical range to [0-1] \n",
        "    plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "Z_HYOXjVTrIl",
        "outputId": "fd9c9311-a233-4e1f-82b5-3e8f243340ab"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'20.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-WtGXxxTvYt",
        "outputId": "22f594d8-a483-481e-be16-3a0d29e7fe7d"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('20.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvyXVhXmT-zN",
        "outputId": "5dda5e9d-2c41-4a4d-aedb-c3f144c41167"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 3s 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_15feoFgUA8w",
        "outputId": "1afea868-9db3-4a2b-dd0b-74e24c3da0b6"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "metadata": {
        "id": "D7M6Ah9e4XkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "haxakylcmG9Q"
      },
      "outputs": [],
      "source": [
        "# Model 2 using new hidden sizes\n",
        "# Baseline with LR 0.001\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "        model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "        model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "        model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "xjQoNClGmH6F"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_cnn(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "ZzE8wn1RmK9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8a4d54-b95e-4ff9-cb15-c8b21173f458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.4129 - accuracy: 0.8508 - val_loss: 28.2334 - val_accuracy: 0.8941\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 110s 59ms/step - loss: 0.2692 - accuracy: 0.9040 - val_loss: 24.1600 - val_accuracy: 0.8916\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 110s 59ms/step - loss: 0.2280 - accuracy: 0.9169 - val_loss: 20.0064 - val_accuracy: 0.8941\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 110s 59ms/step - loss: 0.1994 - accuracy: 0.9275 - val_loss: 25.0398 - val_accuracy: 0.8980\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 0.1734 - accuracy: 0.9373 - val_loss: 28.6490 - val_accuracy: 0.8890\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 0.1523 - accuracy: 0.9448 - val_loss: 33.2632 - val_accuracy: 0.8839\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 0.1324 - accuracy: 0.9518 - val_loss: 38.4041 - val_accuracy: 0.8724\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 0.1134 - accuracy: 0.9585 - val_loss: 40.3557 - val_accuracy: 0.8648\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 0.0974 - accuracy: 0.9638 - val_loss: 48.3496 - val_accuracy: 0.8686\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_31 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 7, 7, 96)          55392     \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 4704)              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                47050     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,258\n",
            "Trainable params: 121,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "i5WY-CrUtGBC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "aa66351f-0c48-451a-bab4-459cf4282f2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'2.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hm8W-InLrfY",
        "outputId": "effe1901-5bb6-40da-c550-f755d773cae4"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('2.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHyW9NUrLz3q",
        "outputId": "be5a3e47-a882-4acf-9671-007c8bcf25f1"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 3s 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25-MLtgVOv_m",
        "outputId": "e34c0f93-2445-4f51-879a-7828381f741e"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = X_test[0]\n",
        "fig = plt.figure\n",
        "plt.imshow(image, cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "nu6LSljcMfRs",
        "outputId": "a4a2a543-c319-4a2c-fe78-d9f77736f19e"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "Ny7M7zyRtJzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff1d3ee-f2cd-4013-c6a0-1ab734a7a5c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Test Score: 4.199514389038086\n",
            "Test Accuracy: 0.10199999809265137\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "ZLYq63an3S_-"
      },
      "outputs": [],
      "source": [
        "# Model 2 using new hidden sizes in reverse\n",
        "# Baseline with LR 0.001\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [96, 64, 32] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "# learning rate\n",
        "learningrate = 0.0001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 10\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "        model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "        model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "        model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "qgGRacFP3W2H"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_cnn(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "cGvJ2HS83ZwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2831e811-d28c-48ce-eca4-74aa7d2cfc5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 209s 110ms/step - loss: 0.6781 - accuracy: 0.7597 - val_loss: 55.4699 - val_accuracy: 0.8099\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 206s 110ms/step - loss: 0.4362 - accuracy: 0.8443 - val_loss: 43.7515 - val_accuracy: 0.8418\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 208s 111ms/step - loss: 0.3845 - accuracy: 0.8626 - val_loss: 42.2754 - val_accuracy: 0.8571\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 209s 112ms/step - loss: 0.3538 - accuracy: 0.8741 - val_loss: 51.7203 - val_accuracy: 0.8342\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 214s 114ms/step - loss: 0.3327 - accuracy: 0.8811 - val_loss: 41.3238 - val_accuracy: 0.8661\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 206s 110ms/step - loss: 0.3154 - accuracy: 0.8881 - val_loss: 42.9893 - val_accuracy: 0.8571\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 208s 111ms/step - loss: 0.3015 - accuracy: 0.8926 - val_loss: 49.3268 - val_accuracy: 0.8431\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 206s 110ms/step - loss: 0.2907 - accuracy: 0.8969 - val_loss: 43.7465 - val_accuracy: 0.8495\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 208s 111ms/step - loss: 0.2809 - accuracy: 0.8995 - val_loss: 53.0056 - val_accuracy: 0.8265\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 208s 111ms/step - loss: 0.2737 - accuracy: 0.9018 - val_loss: 44.9544 - val_accuracy: 0.8571\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_34 (Conv2D)          (None, 28, 28, 96)        960       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 14, 14, 96)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 14, 14, 64)        55360     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 7, 7, 32)          18464     \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                15690     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 90,474\n",
            "Trainable params: 90,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "o1G5rnQf3oTm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "6b3ed5bc-9815-4bdc-b26e-cbc6556e3537"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'21.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StT0lRY6SoKh",
        "outputId": "cab73e74-7813-49e4-f5db-abebada42f5d"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('21.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiimz7s-S46P",
        "outputId": "5bbcb66c-1798-4ddf-aa7d-274a1ad11ffe"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 4s 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTOXyalBS7I6",
        "outputId": "16816f0b-a9d0-43a8-c8a0-81b93fa08fff"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = X_test[0]\n",
        "fig = plt.figure\n",
        "plt.imshow(image, cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "9B5_s_e2TAn9",
        "outputId": "aefc8ab9-71ce-4704-fd01-37078cf3f0fd"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sey4MAPmTLel",
        "outputId": "37754504-d6db-4dd5-a6f8-60209c51aa0f"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Test Score: 3.9636292457580566\n",
            "Test Accuracy: 0.10199999809265137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TSq4fF6oUIQN"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Using SGD as optimiser"
      ],
      "metadata": {
        "id": "9p3Ekwa2UIqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 using new hidden sizes\n",
        "# Baseline with LR 0.0001\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.SGD\n",
        "# learning rate\n",
        "learningrate = 0.0001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "        model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "        model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "        model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ],
      "metadata": {
        "id": "snT0NzDHUMsA"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_cnn(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ],
      "metadata": {
        "id": "SY5z_A3jUUgS"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "J1OJEm-JUWsP",
        "outputId": "0ba9bd61-2217-423f-a26c-3495510b8e89"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 110s 58ms/step - loss: 2.2987 - accuracy: 0.1677 - val_loss: 21.4519 - val_accuracy: 0.1684\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 107s 57ms/step - loss: 2.2851 - accuracy: 0.1750 - val_loss: 20.3249 - val_accuracy: 0.1798\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 2.2707 - accuracy: 0.1728 - val_loss: 19.8760 - val_accuracy: 0.1798\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 107s 57ms/step - loss: 2.2528 - accuracy: 0.1907 - val_loss: 19.6576 - val_accuracy: 0.1888\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 112s 60ms/step - loss: 2.2277 - accuracy: 0.2688 - val_loss: 19.8145 - val_accuracy: 0.2577\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 2.1888 - accuracy: 0.3403 - val_loss: 20.3108 - val_accuracy: 0.3151\n",
            "Epoch 7/20\n",
            " 111/1875 [>.............................] - ETA: 1:42 - loss: 2.1608 - accuracy: 0.3818"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-195-106ad0c9f255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function that tests the model above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddensizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-194-51bc440524cd>\u001b[0m in \u001b[0;36mdo_all\u001b[0;34m(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddensizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n\u001b[0;32m----> 8\u001b[0;31m                         validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmax_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_val_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "sg-XLsjyUYKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'23.model')\n"
      ],
      "metadata": {
        "id": "l76VM42FUYDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('23.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])"
      ],
      "metadata": {
        "id": "kyIQkBOXUX88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "id": "kvMsbR-jUX2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "metadata": {
        "id": "fPMZn1yvUXGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 using new hidden sizes\n",
        "# Baseline with LR 0.001\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.SGD\n",
        "# learning rate\n",
        "learningrate = 0.001\n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "def model_cnn(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=hiddensizes[0], kernel_size=3, strides=1, activation=actfn, padding=\"same\", input_shape=[28, 28, 1]))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    for n in hiddensizes[1:-1]:\n",
        "        model.add(keras.layers.Conv2D(filters=n, kernel_size=3, strides=1, padding=\"same\", activation=actfn)) \n",
        "        model.add(keras.layers.MaxPooling2D(pool_size=2))          # Pool (downsize)\n",
        "        model.add(keras.layers.Conv2D(filters=hiddensizes[-1], kernel_size=3, strides=1, padding=\"same\", activation=actfn))  \n",
        "        model.add(keras.layers.Flatten())                          # unravel into a 1D vector\n",
        "        model.add(keras.layers.Dense(10, activation = \"softmax\"))  # 10 classes for this dataset\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
        "    return model"
      ],
      "metadata": {
        "id": "CE-zs-S-UPLh"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_cnn(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ],
      "metadata": {
        "id": "isLjDVzMUVAA"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "izWI0KQAUajm",
        "outputId": "09a2f7ce-34d5-4e8c-dac3-ded7c919fceb"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            " 756/1875 [===========>..................] - ETA: 1:12 - loss: 2.2650 - accuracy: 0.1677"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-106ad0c9f255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function that tests the model above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddensizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-197-51bc440524cd>\u001b[0m in \u001b[0;36mdo_all\u001b[0;34m(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddensizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n\u001b[0;32m----> 8\u001b[0;31m                         validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmax_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_val_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "ICfbSyCuUc0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'24.model')\n"
      ],
      "metadata": {
        "id": "YUG0VAtUUcsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('24.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])"
      ],
      "metadata": {
        "id": "J87HrxN-UckT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "id": "AxRXQk5DUcby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "metadata": {
        "id": "WBFKGwCOUcT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKO9BKRoUntt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### DNN testing with Adam"
      ],
      "metadata": {
        "id": "fEM_PBWeUoDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN Model 6\n",
        "# Original DNN with increased hidden layer sizes\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.0001 \n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1])) \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "GMYfCWC3owN5"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ],
      "metadata": {
        "id": "osV0Nli5oyJa"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szHc0vjjozsk",
        "outputId": "4eece662-c894-4f40-dbd7-5ffc05ba5cd9"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.8820 - accuracy: 0.7109 - val_loss: 72.9270 - val_accuracy: 0.7857\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5110 - accuracy: 0.8222 - val_loss: 72.7999 - val_accuracy: 0.8023\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4550 - accuracy: 0.8404 - val_loss: 70.9937 - val_accuracy: 0.8214\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4277 - accuracy: 0.8492 - val_loss: 66.4133 - val_accuracy: 0.8393\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4085 - accuracy: 0.8557 - val_loss: 67.5202 - val_accuracy: 0.8329\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3943 - accuracy: 0.8609 - val_loss: 68.3111 - val_accuracy: 0.8329\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3837 - accuracy: 0.8635 - val_loss: 56.8729 - val_accuracy: 0.8482\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3739 - accuracy: 0.8671 - val_loss: 73.2520 - val_accuracy: 0.8329\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3664 - accuracy: 0.8686 - val_loss: 67.9660 - val_accuracy: 0.8329\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3583 - accuracy: 0.8709 - val_loss: 62.0348 - val_accuracy: 0.8457\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3517 - accuracy: 0.8737 - val_loss: 61.9188 - val_accuracy: 0.8482\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3458 - accuracy: 0.8760 - val_loss: 64.1466 - val_accuracy: 0.8431\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_14 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 96)                6240      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 25)                2425      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,897\n",
            "Trainable params: 35,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'600.model')"
      ],
      "metadata": {
        "id": "mPJtzzH7o2cq"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "Y842JgajuR-F"
      },
      "outputs": [],
      "source": [
        "# DNN Model 6\n",
        "# Original DNN with increased hidden layer sizes\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.Adam\n",
        "learningrate = 0.001 \n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1])) \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "PzvR6A_VuaWS"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "_FN0hjB7ua6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2510a1-c0ef-4720-bc3f-843b87b3fbfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5452 - accuracy: 0.8081 - val_loss: 50.5241 - val_accuracy: 0.8380\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3900 - accuracy: 0.8589 - val_loss: 50.0739 - val_accuracy: 0.8546\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3584 - accuracy: 0.8694 - val_loss: 45.9298 - val_accuracy: 0.8635\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3375 - accuracy: 0.8751 - val_loss: 85.1777 - val_accuracy: 0.7985\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3244 - accuracy: 0.8804 - val_loss: 60.2348 - val_accuracy: 0.8202\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3112 - accuracy: 0.8857 - val_loss: 48.4500 - val_accuracy: 0.8520\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3017 - accuracy: 0.8899 - val_loss: 69.2807 - val_accuracy: 0.8278\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2911 - accuracy: 0.8934 - val_loss: 40.4725 - val_accuracy: 0.8482\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_15 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 96)                6240      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 25)                2425      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,897\n",
            "Trainable params: 35,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "jzkDbRK2vG5U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "a354b5ab-8646-4bd8-fe73-27481fec23ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'60.model')"
      ],
      "metadata": {
        "id": "VlsC40a5TVcX"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('6.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gqYMe0_TVRU",
        "outputId": "a4643892-6ac9-4dbc-e7a2-2a874d81172c"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7KQOJmyTUgJ",
        "outputId": "7e394425-8fea-4209-8b35-9b1d1175a79b"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zz0dN1aTTDN",
        "outputId": "500b42a4-4bf4-42c8-9627-5a13e5340a0e"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Test Score: 4.080015182495117\n",
            "Test Accuracy: 0.10199999809265137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### DNN with SGD"
      ],
      "metadata": {
        "id": "9Fj1Gpd9U2kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN Model 6\n",
        "# Original DNN with increased hidden layer sizes\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.SGD\n",
        "learningrate = 0.0001 \n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1])) \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "morUZYtEo5N2"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ],
      "metadata": {
        "id": "t7XYr8ySo65E"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IITjX4ho8rQ",
        "outputId": "e4b6cdc9-3b56-4d91-8f23-0726cc5e1795"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 3.1949 - accuracy: 0.0555 - val_loss: 90.2411 - val_accuracy: 0.0918\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.0088 - accuracy: 0.0900 - val_loss: 103.5868 - val_accuracy: 0.0906\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.7902 - accuracy: 0.0994 - val_loss: 94.5259 - val_accuracy: 0.1046\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.5182 - accuracy: 0.1468 - val_loss: 46.5684 - val_accuracy: 0.1990\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2690 - accuracy: 0.3135 - val_loss: 37.7217 - val_accuracy: 0.3367\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.0728 - accuracy: 0.3948 - val_loss: 36.5652 - val_accuracy: 0.4018\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9052 - accuracy: 0.4516 - val_loss: 32.9995 - val_accuracy: 0.4515\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.7552 - accuracy: 0.5176 - val_loss: 32.1353 - val_accuracy: 0.5026\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6221 - accuracy: 0.5606 - val_loss: 32.2718 - val_accuracy: 0.5485\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5053 - accuracy: 0.5886 - val_loss: 35.5770 - val_accuracy: 0.5561\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4060 - accuracy: 0.6033 - val_loss: 39.5523 - val_accuracy: 0.5880\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.3236 - accuracy: 0.6126 - val_loss: 39.5967 - val_accuracy: 0.6122\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.2548 - accuracy: 0.6211 - val_loss: 43.6273 - val_accuracy: 0.6224\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1966 - accuracy: 0.6256 - val_loss: 45.2578 - val_accuracy: 0.6250\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1470 - accuracy: 0.6314 - val_loss: 48.5282 - val_accuracy: 0.6352\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1040 - accuracy: 0.6361 - val_loss: 51.6427 - val_accuracy: 0.6327\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.0667 - accuracy: 0.6403 - val_loss: 53.3638 - val_accuracy: 0.6378\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0339 - accuracy: 0.6447 - val_loss: 53.8287 - val_accuracy: 0.6288\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.0051 - accuracy: 0.6496 - val_loss: 55.7585 - val_accuracy: 0.6288\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9798 - accuracy: 0.6538 - val_loss: 57.7491 - val_accuracy: 0.6403\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 96)                6240      \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 25)                2425      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,897\n",
            "Trainable params: 35,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'611.model')\n"
      ],
      "metadata": {
        "id": "vgTDzMK-o_LE"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "4TK69e8-UzVC"
      },
      "outputs": [],
      "source": [
        "# DNN Model 6\n",
        "# Original DNN with increased hidden layer sizes\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.SGD\n",
        "learningrate = 0.001 \n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1])) \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "QzmUr81FU6rH"
      },
      "outputs": [],
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqstKAgbU8L7",
        "outputId": "d87f559c-55aa-4d4d-8aa8-50570581a71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.2439 - accuracy: 0.3419 - val_loss: 46.6494 - val_accuracy: 0.5727\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0883 - accuracy: 0.6178 - val_loss: 63.9563 - val_accuracy: 0.6365\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8811 - accuracy: 0.6768 - val_loss: 70.8298 - val_accuracy: 0.6888\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7839 - accuracy: 0.7169 - val_loss: 75.9876 - val_accuracy: 0.7156\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7187 - accuracy: 0.7450 - val_loss: 71.4503 - val_accuracy: 0.7258\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6686 - accuracy: 0.7639 - val_loss: 75.5049 - val_accuracy: 0.7347\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6296 - accuracy: 0.7770 - val_loss: 77.9916 - val_accuracy: 0.7449\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5997 - accuracy: 0.7868 - val_loss: 79.1282 - val_accuracy: 0.7602\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5763 - accuracy: 0.7953 - val_loss: 75.8833 - val_accuracy: 0.7666\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5577 - accuracy: 0.8016 - val_loss: 76.9401 - val_accuracy: 0.7704\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5413 - accuracy: 0.8089 - val_loss: 76.9195 - val_accuracy: 0.7793\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5283 - accuracy: 0.8131 - val_loss: 78.6658 - val_accuracy: 0.7819\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5169 - accuracy: 0.8180 - val_loss: 92.8632 - val_accuracy: 0.7717\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5068 - accuracy: 0.8217 - val_loss: 90.6446 - val_accuracy: 0.7704\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4978 - accuracy: 0.8256 - val_loss: 81.2138 - val_accuracy: 0.7832\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4899 - accuracy: 0.8281 - val_loss: 89.6788 - val_accuracy: 0.7717\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4832 - accuracy: 0.8298 - val_loss: 82.8367 - val_accuracy: 0.7908\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4766 - accuracy: 0.8314 - val_loss: 75.0142 - val_accuracy: 0.7946\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4707 - accuracy: 0.8338 - val_loss: 80.8846 - val_accuracy: 0.7934\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4655 - accuracy: 0.8351 - val_loss: 84.1072 - val_accuracy: 0.7844\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 96)                6240      \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 25)                2425      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,897\n",
            "Trainable params: 35,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "orsSZDY6U9n5",
        "outputId": "ad322252-8a19-4f6c-d0f3-fe7afef897f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'61.model')\n"
      ],
      "metadata": {
        "id": "qD6u-Hp_VUB4"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('61.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQflthjPVabV",
        "outputId": "879bc806-deda-4475-851c-3ac1bb10da5d"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrobV2t0VcGP",
        "outputId": "29c6ff5c-65a4-401b-da9b-b398b98487ae"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iAsXuRXVfIr",
        "outputId": "6d83a08e-5c6f-492f-9cb7-397653ca4288"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Test Score: 3.0443813800811768\n",
            "Test Accuracy: 0.10199999809265137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN Model 6\n",
        "# Original DNN with increased hidden layer sizes\n",
        "\n",
        "n_train = 60000\n",
        "n_valid = 784\n",
        "# number and size of hidden layers\n",
        "hiddensizes = [32, 64, 96] \n",
        "# activation function to be used by hidden layers\n",
        "actfn = \"relu\"\n",
        "# optimiser and learning rate\n",
        "optimizer = keras.optimizers.SGD\n",
        "learningrate = 0.0001 \n",
        "# size of batch and number of epochs\n",
        "batch_size = 50\n",
        "n_epochs = 20\n",
        "\n",
        "# and the function\n",
        "def model_dense(hiddensizes, actfn, optimizer, learningrate):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape = [28, 28, 1])) \n",
        "    for n in hiddensizes:\n",
        "        model.add(keras.layers.Dense(n, activation = actfn))\n",
        "    model.add(keras.layers.Dense(25, activation = \"softmax\")) \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JfGk8fAXtxUN"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size, further_callbacks=[]):\n",
        "    if further_callbacks != []:\n",
        "        callbacks = further_callbacks\n",
        "    else:\n",
        "        callbacks = [early_stopping_cb]\n",
        "    model = model_dense(hiddensizes, actfn, optimizer, learningrate)\n",
        "    history = model.fit(X_train[:n_train,:,:], y_train[:n_train], epochs=n_epochs, callbacks = callbacks,\n",
        "                        validation_data=(X_valid[:n_valid,:,:], y_valid[:n_valid]))\n",
        "    max_val_acc = np.max(history.history['val_accuracy'])\n",
        "    return (max_val_acc, history, model)"
      ],
      "metadata": {
        "id": "QmVRDZiNt_iP"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that tests the model above\n",
        "valacc, history, model = do_all(hiddensizes, actfn, optimizer, learningrate, n_train, n_valid, n_epochs, batch_size)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrsrm7sItx0O",
        "outputId": "fdb08415-5839-45a9-d023-b00c7f7cbf87"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 3.1568 - accuracy: 0.0741 - val_loss: 70.0522 - val_accuracy: 0.1186\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.9506 - accuracy: 0.1605 - val_loss: 84.4899 - val_accuracy: 0.1620\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.6825 - accuracy: 0.1957 - val_loss: 94.7772 - val_accuracy: 0.2245\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3996 - accuracy: 0.2646 - val_loss: 75.3571 - val_accuracy: 0.2717\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.1760 - accuracy: 0.3358 - val_loss: 55.0887 - val_accuracy: 0.3967\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.0062 - accuracy: 0.4436 - val_loss: 52.0627 - val_accuracy: 0.4579\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.8564 - accuracy: 0.4942 - val_loss: 52.3482 - val_accuracy: 0.5102\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7149 - accuracy: 0.5234 - val_loss: 52.1275 - val_accuracy: 0.5497\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5823 - accuracy: 0.5486 - val_loss: 53.7110 - val_accuracy: 0.5727\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4618 - accuracy: 0.5745 - val_loss: 56.4004 - val_accuracy: 0.5957\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.3562 - accuracy: 0.5979 - val_loss: 55.2149 - val_accuracy: 0.6046\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2667 - accuracy: 0.6158 - val_loss: 56.9766 - val_accuracy: 0.6250\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1917 - accuracy: 0.6312 - val_loss: 57.1355 - val_accuracy: 0.6416\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.1293 - accuracy: 0.6415 - val_loss: 58.3334 - val_accuracy: 0.6467\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0773 - accuracy: 0.6510 - val_loss: 60.9973 - val_accuracy: 0.6607\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0337 - accuracy: 0.6577 - val_loss: 61.2430 - val_accuracy: 0.6620\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9965 - accuracy: 0.6642 - val_loss: 62.7556 - val_accuracy: 0.6633\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9646 - accuracy: 0.6691 - val_loss: 63.7577 - val_accuracy: 0.6645\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9370 - accuracy: 0.6750 - val_loss: 63.9691 - val_accuracy: 0.6658\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9127 - accuracy: 0.6787 - val_loss: 64.7239 - val_accuracy: 0.6722\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 96)                6240      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 25)                2425      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,897\n",
            "Trainable params: 35,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "Xsryc6NjuDRz",
        "outputId": "0608e7d1-8f5f-4514-9f00-cacde3bd3760"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "save_model(model,'611.model')\n"
      ],
      "metadata": {
        "id": "iACn3PiBuEFs"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('611.model', compile=False)\n",
        "saved_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "predictions = saved_model.predict([X_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ZV0abzuDqx",
        "outputId": "05cc3432-4571-426c-da02-1583d18e11c4"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[4600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9lAJvswuPoV",
        "outputId": "48d94de1-cf81-45b1-d842-a5e4f1e35fba"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test Score:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qny2dcBuVay",
        "outputId": "88b7a7b2-2ea4-4409-9954-38131fad57a9"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Test Score: 3.0334854125976562\n",
            "Test Accuracy: 0.10199999809265137\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}